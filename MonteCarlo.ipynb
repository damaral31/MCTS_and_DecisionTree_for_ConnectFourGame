{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd3bdff2",
   "metadata": {},
   "source": [
    "# Monte Carlo Tree Search (MCTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2da395",
   "metadata": {},
   "source": [
    "Este é o modelo que constitui o cerne deste projeto. O algoritmo pode ser dividido em 4 fases:\n",
    "\n",
    "1. **Seleção:** A partir da raiz, percorre-se a árvore selecionando sucessivamente os nós filhos de acordo com uma política (por exemplo, UCT) até chegar a um nó folha.\n",
    "\n",
    "2. **Expansão:** Se o nó folha não representa um estado terminal, um ou mais filhos são criados e adicionados à árvore.\n",
    "\n",
    "3. **Simulação:** A partir do novo nó, realiza-se uma simulação (jogadas aleatórias) até que seja alcançado um estado terminal.\n",
    "\n",
    "4. **Retropropagação:** O resultado da simulação é propagado de volta pela árvore, atualizando os nós visitados de acordo com a estatística selecionada.\n",
    "\n",
    "Esses passos repetidos um número predefinidos de vezes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b25aa8",
   "metadata": {},
   "source": [
    "## Aplicação Prática"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ebabcb",
   "metadata": {},
   "source": [
    "No contexto deste projeto, cada nó representa uma posição do tabuleiro, e cada aresta uma jogada válida, tendo portanto cada nó como seus filhos os estados que resultam de jogadas válidas. Assim sendo, o modelo é chamado uma vez por jogada, dado o tabuleiro atual, simula uma quantidade consideravél de jogos possíveis e retorna a coluna à qual estiver associada o maior score UCB (estatística explicada mais abaixo).\n",
    "\n",
    "Segue-se o código da classe MCTS como descrito [neste ficheiro](MCTS/MCTS.py), e uma breve descrição do seu funcionamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87902b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from typing import Tuple, Any, List, Union\n",
    "\n",
    "import utils.config as config\n",
    "\n",
    "from Game.ConnectFour import ConnectFour\n",
    "from MCTS.node import Node\n",
    "\n",
    "\n",
    "class MonteCarlo_Single(object):\n",
    "    \"\"\"\n",
    "    Monte Carlo Tree Search algorithm.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    search(root: Node) -> int\n",
    "        Search the best move from the root node.\n",
    "     selection(node: Node, turn: int) -> (Node, int)\n",
    "        Select the best node to expand.\n",
    "    expansion(node: Node) -> Node\n",
    "        Expand the node by adding a new child.\n",
    "    simulation(state_init: ConnectFour, turn: int) -> float\n",
    "        Simulate a random game from the initial state.\n",
    "    backpropagation(node: Node, reward: float, turn: int) -> None\n",
    "        Backpropagate the reward of the simulation to the root node.\n",
    "    best_child(node: Node) -> Node\n",
    "        Return the best child of the node.\n",
    "    \"\"\"\n",
    "    def __init__(self, iteration: int = config.ITERATION, exploration: float = config.EXPLORATION, debug: bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the Monte Carlo Tree Search algorithm.\n",
    "        \"\"\"\n",
    "        self.iteration = iteration\n",
    "        self.exploration = exploration\n",
    "        if debug:\n",
    "            print(f\"Monte Carlo Tree Search: iteration={iteration}, exploration={exploration}\")\n",
    "\n",
    "    def search(self, root: Node) -> tuple[Any, list[Any]]:\n",
    "        \"\"\"\n",
    "        Search the best move from the root node.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        root: the root node of the search tree\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int: the best move\n",
    "        \"\"\"\n",
    "        for _ in range(self.iteration):\n",
    "            node, turn = self.selection(root, -1)\n",
    "            reward = self.simulation(node.state, turn)\n",
    "            self.backpropagation(node, reward, turn)\n",
    "\n",
    "        prob = []\n",
    "        for child in root.children:\n",
    "            prob.append(child.visits / root.visits)\n",
    "\n",
    "        ans = max(root.children, key=lambda c: c.visits)\n",
    "        return ans.state.last_move[1], prob\n",
    "\n",
    "    def selection(self, node: Node, turn: int) -> tuple[Node, int]:\n",
    "        \"\"\"\n",
    "        Select the best node to expand.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        node: the node to start the selection from\n",
    "        turn: the turn of the player who played the move leading to this node\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        node: the node to expand\n",
    "        turn: the turn of the player who played the move leading to this node\n",
    "        \"\"\"\n",
    "        while not node.is_terminal():\n",
    "            if not node.fully_explored():\n",
    "                return self.expansion(node), -1 * turn\n",
    "            else:\n",
    "                node = self.best_child(node)\n",
    "                turn *= -1\n",
    "\n",
    "        return node, turn\n",
    "\n",
    "    @staticmethod\n",
    "    def expansion(node: Node) -> Node:\n",
    "        \"\"\"\n",
    "        Expand the node by adding a new child.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        node: the node to expand\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        node: the new child\n",
    "        \"\"\"\n",
    "        free_cols = node.state.legal_moves()\n",
    "\n",
    "        for col in free_cols:\n",
    "            if col not in node.children_move:\n",
    "                new_state = node.state.copy()\n",
    "                new_state.play(col)\n",
    "                node.add_child(new_state, col)\n",
    "                break\n",
    "\n",
    "        return node.children[-1]\n",
    "\n",
    "    @staticmethod\n",
    "    def simulation(state_init: ConnectFour, turn: int) -> float:\n",
    "        \"\"\"\n",
    "        Simulate a random game from the initial state.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state_init: the initial state of the game\n",
    "        turn: the turn of the player who played the move leading to this node\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        reward: the reward of the simulated game\n",
    "        \"\"\"\n",
    "        state = state_init.copy()\n",
    "\n",
    "        while not state.is_over():\n",
    "            state.play(random.choice(state.legal_moves()))\n",
    "            turn *= -1\n",
    "\n",
    "        reward_bool = state.is_over()\n",
    "\n",
    "        if reward_bool and turn == -1:\n",
    "            reward = 1.0\n",
    "        elif reward_bool and turn == 1:\n",
    "            reward = -1.0\n",
    "        else:\n",
    "            reward = 0.0\n",
    "        return reward\n",
    "\n",
    "    @staticmethod\n",
    "    def backpropagation(node: Node, reward: float, turn: int) -> None:\n",
    "        \"\"\"\n",
    "        Backpropagate the reward of the simulation to the root node.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        node: the node to start the backpropagation from\n",
    "        reward: the reward of the simulation\n",
    "        turn: the turn of the player who played the move leading to this node\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        none\n",
    "        \"\"\"\n",
    "        while node is not None:\n",
    "            node.visits += 1\n",
    "            node.reward -= turn * reward\n",
    "            node = node.parent\n",
    "            turn *= -1\n",
    "\n",
    "    def best_child(self, node: Node) -> Node:\n",
    "        \"\"\"\n",
    "        Return the best child of the node.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        node: the node to select the best child from\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        node: the best child\n",
    "        \"\"\"\n",
    "        best_score = -float(\"inf\")\n",
    "        best_children = None\n",
    "\n",
    "        for child in node.children:\n",
    "            exploitation = child.reward / child.visits\n",
    "            exploration = math.sqrt(math.log2(node.visits) / child.visits)\n",
    "            score = exploitation + self.exploration * exploration\n",
    "\n",
    "            if score == best_score:\n",
    "                if child.visits > best_children.visits:\n",
    "                    best_children = child\n",
    "            elif score > best_score:\n",
    "                best_score = score\n",
    "                best_children = child\n",
    "\n",
    "        return best_children"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8c2212",
   "metadata": {},
   "source": [
    "### Explicação das Funções da Classe\n",
    "\n",
    "- **`__init__`**  \n",
    "    Inicializa o algoritmo MCTS, definindo o número de iterações e o parâmetro de exploração.\n",
    "\n",
    "- **`search`**  \n",
    "    Executa o ciclo principal do MCTS: seleção, expansão, simulação e retropropagação, retornando a melhor jogada e as probabilidades associadas a cada filho da raiz.\n",
    "\n",
    "- **`selection`**  \n",
    "    Percorre a árvore a partir de um nó, seguindo a política de seleção (ex: UCB), até encontrar um nó folha ou não totalmente explorado.\n",
    "\n",
    "- **`expansion`**  \n",
    "    Expande um nó folha, criando e adicionando um novo filho correspondente a uma jogada ainda não explorada.\n",
    "\n",
    "- **`simulation`**  \n",
    "    Realiza uma simulação (jogo aleatório) a partir do estado atual até um estado terminal, retornando a recompensa do resultado.\n",
    "\n",
    "- **`backpropagation`**  \n",
    "    Propaga o resultado da simulação de volta pela árvore, atualizando as estatísticas dos nós visitados.\n",
    "\n",
    "- **`best_child`**  \n",
    "    Seleciona o melhor filho de um nó com base no critério de exploração/exploração (UCB), para guiar a busca nas próximas iterações.\n",
    "\n",
    "Ou seja, a escolha de uma jogada (executada pela função `search`) executa as 4 fases mencionadas acima, iteradas tantas vezes quantas as definidas no ficheiro [config.py](utils/config.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7e526a",
   "metadata": {},
   "source": [
    "### UCB\n",
    "Utilizamos como métrica para avaliação dos nodes o UCB, a estatística mais comum em implementações de MCTS, e que pode ser descrita pela seguinte fórmula:\n",
    "\n",
    "$$\n",
    "UCB = \\frac{w_i}{s_i} + c \\sqrt{\\frac{\\ln s_p}{s_i}}\n",
    "$$\n",
    "\n",
    "onde:\n",
    "\n",
    "- $w_i$: número de vitórias do nó $i$\n",
    "- $s_i$: número de simulações do nó $i$\n",
    "- $s_p$: número de simulações do nó pai\n",
    "- $c$: parâmetro de *exploitation*\n",
    "\n",
    "Em que $c$ constitui uma constante que equilibra o quanto a *exploration* é favorecida sobre a *exploitation*. Esta constante, neste projeto está também definida no ficheiro de [configuração](utils/config.py) e toma o valor de $1.414$, isto é, aproximadamente $\\sqrt{2}$, também um valor muito usado por defeito nestas áreas.\n",
    "\n",
    "Em específico, o UCB é calculado nestas linhas do ficheiro [MCTS.py](MCTS/MCTS.py), na função `best_child`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e49778",
   "metadata": {},
   "source": [
    "```python\n",
    "exploitation = child.reward / child.visits\n",
    "exploration = math.sqrt(math.log2(node.visits) / child.visits)\n",
    "score = exploitation + self.exploration * exploration\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6953120b",
   "metadata": {},
   "source": [
    "### Escolha da próxima jogada\n",
    "Acabadas as iterações do MCTS, cada jogada válida tem a si associada dois valores:\n",
    "\n",
    "* **Visited (V):** Representa a quantidade de simulações feitas sobre esse nó nas iterações de de MCTS. Vai ser, portanto, $n \\mid n \\in \\mathbb{N},\\ 0 \\leq n \\leq \\text{iter}$ em que $iter$ é o número de iterações do MCTS.\n",
    "* **Reward:** Representa o somatório dos rewards das iterações de MTCS. Um reward em cada iteração é definido por:\n",
    "    * **1** se o próprio ganha;\n",
    "    * **0** se há um empate;\n",
    "    * **-1** se o adversário ganha.\n",
    "\n",
    "Resta apenas definir o critério de escolha, isto é, se consideramos o melhor lance aquele que foi o mais visitado, o mais recompensado ou um equilíbrio das duas características.\n",
    "\n",
    "Testando as várias hipóteses, no entanto, verificamos que a melhor performance é obtida ao priorizar pelos visitados. Isto provavelmente deve-se a um nó ser mais visitado significar que obteve mais score UCB mais vezes, provando ser o mais promissor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce85b508",
   "metadata": {},
   "source": [
    "### Tempo de execução\n",
    "Ao constatar, naturalmente, que um número superior de iterações significa uma melhor performance, tentou-se executar modelos com mais e mais iterações. No entanto, neste processo o modelo começou também a demorar cada vez mais tempo a calcular a sua próxima jogada, o que piora a experiência de jogo.\n",
    "\n",
    "No sentido de corrigir isto, implementou-se uma outra classe de MCTS que utiliza *paralel processing*, executando várias iterações ao mesmo tempo, e sendo por isso significativamente mais rápido que a sua contraparte, que utiliza apenas um *core* para todas as tarefas.\n",
    "\n",
    "Eis essa outra implementação, denominada `MonteCarlo` no ficheiro [MCTS_optimized.py](MCTS/MCTS_optimized.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a542a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import os\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from typing import Tuple, Any, Dict\n",
    "\n",
    "import utils.config as config\n",
    "from Game.ConnectFour import ConnectFour\n",
    "from MCTS.node import Node\n",
    "\n",
    "\n",
    "def worker_mcts(state: ConnectFour, iterations: int, exploration: float) -> Dict[int, Tuple[float, int]]:\n",
    "    \"\"\"\n",
    "    Each worker runs its own mini-MCTS rooted at the same state.\n",
    "    Returns: {move: (total_reward, total_visits)}\n",
    "    \"\"\"\n",
    "    root = Node(state.copy())\n",
    "\n",
    "    def selection(node: Node, turn: int) -> Tuple[Node, int]:\n",
    "        while not node.is_terminal():\n",
    "            if not node.fully_explored():\n",
    "                return expansion(node), -1 * turn\n",
    "            node = best_child(node)\n",
    "            turn *= -1\n",
    "        return node, turn\n",
    "\n",
    "    def expansion(node: Node) -> Node:\n",
    "        for col in node.state.legal_moves():\n",
    "            if col not in node.children_move:\n",
    "                new_state = node.state.copy()\n",
    "                new_state.play(col)\n",
    "                node.add_child(new_state, col)\n",
    "                break\n",
    "        return node.children[-1]\n",
    "\n",
    "    def simulation(state: ConnectFour, turn: int, max_depth: int = 20) -> float:\n",
    "        state = state.copy()\n",
    "        moves = 0\n",
    "        while not state.is_over() and moves < max_depth:\n",
    "            legal = state.legal_moves()\n",
    "            if 3 in legal:\n",
    "                state.play(3)\n",
    "            else:\n",
    "                state.play(random.choice(legal))\n",
    "            turn *= -1\n",
    "            moves += 1\n",
    "\n",
    "        if state.is_over():\n",
    "            return 1.0 if turn == -1 else -1.0\n",
    "        return 0.0\n",
    "\n",
    "    def backpropagation(node: Node, reward: float, turn: int) -> None:\n",
    "        while node is not None:\n",
    "            node.visits += 1\n",
    "            node.reward -= turn * reward\n",
    "            node = node.parent\n",
    "            turn *= -1\n",
    "\n",
    "    def best_child(node: Node) -> Node:\n",
    "        best_score = -float(\"inf\")\n",
    "        best_node = None\n",
    "        log_visits = math.log(node.visits + 1)\n",
    "        for child in node.children:\n",
    "            exploit = child.reward / (child.visits + 1e-8)\n",
    "            explore = math.sqrt(log_visits / (child.visits + 1e-8))\n",
    "            score = exploit + exploration * explore\n",
    "\n",
    "            if score == best_score:\n",
    "                if child.visits >= best_node.visits:\n",
    "                    best_node = child\n",
    "            elif score > best_score:\n",
    "                best_score = score\n",
    "                best_node = child\n",
    "        return best_node\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        node, turn = selection(root, -1)\n",
    "        reward = simulation(node.state, turn)\n",
    "        backpropagation(node, reward, turn)\n",
    "\n",
    "    move_stats = {}\n",
    "    for _, child in enumerate(root.children):\n",
    "        move = child.state.last_move[1]\n",
    "        move_stats[move] = (child.reward, child.visits)\n",
    "\n",
    "    return move_stats\n",
    "\n",
    "\n",
    "class MonteCarlo:\n",
    "\n",
    "\n",
    "    def __init__(self, iteration: int = config.ITERATION, exploration: float = config.EXPLORATION, debug: bool = False):\n",
    "        \n",
    "        self.iteration = iteration\n",
    "        self.exploration = exploration\n",
    "        self.cpu_cores = max(1, os.cpu_count() or 1)\n",
    "        self.debug = debug\n",
    "\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"Using {self.cpu_cores} CPU cores for MCTS.\")\n",
    "            print(f\"Iterations per worker: {self.iteration // self.cpu_cores}\")\n",
    "            print(f\"Exploration factor: {self.exploration}\")\n",
    "            print(f\"Total iterations: {self.iteration}\")\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "    def search(self, root: Node) -> tuple[Any, list[Any]]:\n",
    "        iterations_per_worker = self.iteration // self.cpu_cores\n",
    "\n",
    "        with ProcessPoolExecutor(max_workers=self.cpu_cores) as executor:\n",
    "            futures = [executor.submit(worker_mcts, root.state, iterations_per_worker, self.exploration)\n",
    "                       for _ in range(self.cpu_cores)]\n",
    "\n",
    "            all_stats = [f.result() for f in futures]\n",
    "\n",
    "        merged_stats: Dict[int, Tuple[float, int]] = {}\n",
    "\n",
    "        for stat in all_stats:\n",
    "            for move, (reward, visits) in stat.items():\n",
    "                if move not in merged_stats:\n",
    "                    merged_stats[move] = (reward, visits)\n",
    "                else:\n",
    "                    r, v = merged_stats[move]\n",
    "                    merged_stats[move] = (r + reward, v + visits)\n",
    "\n",
    "        for move, (reward, visits) in merged_stats.items():\n",
    "            found = False\n",
    "            for child in root.children:\n",
    "                if child.state.last_move[1] == move:\n",
    "                    child.reward += reward\n",
    "                    child.visits += visits\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                new_state = root.state.copy()\n",
    "                new_state.play(move)\n",
    "                new_child = Node(new_state, root)\n",
    "                new_child.reward = reward\n",
    "                new_child.visits = visits\n",
    "                root.children.append(new_child)\n",
    "                root.children_move.append(move)\n",
    "            root.visits += visits\n",
    "\n",
    "        prob = [child.visits / root.visits for child in root.children]\n",
    "\n",
    "        ans = max(root.children, key=lambda c: c.visits)\n",
    "        return ans.state.last_move[1], prob\n",
    "\n",
    "    def best_child(self, node: Node) -> Node:\n",
    "        best_score = -float(\"inf\")\n",
    "        best_children = None\n",
    "        log_parent_visits = math.log(node.visits + 1)\n",
    "\n",
    "        for child in node.children:\n",
    "            exploitation = child.reward / (child.visits + 1e-8)\n",
    "            exploration = math.sqrt(log_parent_visits / (child.visits + 1e-8))\n",
    "            score = exploitation + self.exploration * exploration\n",
    "\n",
    "            if score == best_score:\n",
    "                if child.visits >= best_children.visits:\n",
    "                    best_children = child\n",
    "            elif score > best_score:\n",
    "                best_score = score\n",
    "                best_children = child\n",
    "\n",
    "        return best_children"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486bfa81",
   "metadata": {},
   "source": [
    "Mesmo assim, provou-se que *paralel processing* não é sempre a solução mais rápida. Isto acontece porque, essencialmente cada *core* do CPU está a realizar MCTS na sua própria árvore e, apenas quando **todos os *cores*** já tenham acabado as suas tarefas é que todas as árvores podem ser unidas, o que computacionalmente é trabalhoso.\n",
    "\n",
    "Assim, estudando este tema mais a fundo, chegou-se a conclusão que a classe `MonteCarlo` é mais eficiente que a class `MCTS` a partir das **5000 iterações**. Assim sendo, dependedo do modo de jogo selecionado, e dependendo da dificuldade selecionada (ou do número de iterações selecionadas no caso de AI vs AI) seleciona-se o modelo mais rápido para a situação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24731593",
   "metadata": {},
   "source": [
    "### Visualização da árvore\n",
    "\n",
    "Finalmente, no sentido de melhor compreender o funcionamento do modelo, e mesmo para *debugging*, criou-se um ficheiro [Visualize_MCtree.py](utils/Visualize_MCtree.py) que, ao ser implementado na [GameMain](GameMain.py) permite ao jogador ativar uma nova funcionalidade do **Modo de Debugging**.\n",
    "\n",
    "Este modo ativa prints de debug, que contêm informações como:\n",
    "\n",
    "- O tempo de resposta da IA\n",
    "- Quantos *cores* do CPU estão a ser usados (se estiver a ser usado mais que um)\n",
    "- O *score* dos vários nós\n",
    "- Entre outros\n",
    "\n",
    "Para além disso, selecionando o modo Player vs AI e jogando contra o modelo, a cada lance feito pelo MTCS, desenhamos um grafo que representa o estado atual e os próximos estados possíveis, bem como as estatísticas a eles associados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
