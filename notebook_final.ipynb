{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d501b7a8",
   "metadata": {},
   "source": [
    "# Notebook Final\n",
    "\n",
    "Este documento tem como objetivo estruturar e documentar o projeto desenvolvido no âmbito da unidade curricular de **Inteligência Artificial**.  \n",
    "\n",
    "Ao longo deste notebook, serão abordadas as decisões tomadas durante o desenvolvimento do trabalho, detalhadas as implementações dos algoritmos utilizados e apresentadas as conclusões obtidas a partir dos resultados alcançados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59191205",
   "metadata": {},
   "source": [
    "## Main do Graphical User Interface (GUI)\n",
    "\n",
    "Apesar da recomendação inicial, decidiu-se implementar uma **interface gráfica com Pygame**, pois tornará o jogo visulamente mais apelativo.<br>\n",
    "A célula de código abaixo é responsável por executar as implementações do jogo, das quais se destacam:\n",
    "- **Player vs Player -** Jogar um jogo de 4 em linha contra um oponente humano;\n",
    "- **Player vs AI -** Jogar um jogo de 4 em linha contra um algoritmo de Monte Carlo Tree Search, podendo escolher a dificuldade do algoritmo;\n",
    "- **AI vs AI -** Observar um jogo de Monte Carlo vs Monte Carlo, podendo escolher o número de iterações para cada modelo;\n",
    "- **Board Editor -** Editar um tabuleiro de 4 em Linha e, se a posição for válida, escolher umas das implementações de Decision Tree para prever o que o Monte Carlo jogaria na posição imputada.\n",
    "\n",
    "> **Nota:** é necessário reiniciar o kernel para voltar a correr a GUI. Quando fechar o jogo, irá retornar um erro por causa comunicação entre dependências dos ficheiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29399050",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mGameMain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConnectFourGUI\n\u001b[0;32m      3\u001b[0m gui \u001b[38;5;241m=\u001b[39m ConnectFourGUI()\n\u001b[1;32m----> 4\u001b[0m gui\u001b[38;5;241m.\u001b[39mmainMenu()\n",
      "File \u001b[1;32mc:\\Users\\diogo\\OneDrive\\Documents\\GitHub\\MCTS_and_DecisionTree_for_ConnectFourGame\\GameMain.py:355\u001b[0m, in \u001b[0;36mConnectFourGUI.mainMenu\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m pygame\u001b[38;5;241m.\u001b[39mQUIT:\n\u001b[0;32m    354\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mquit()\n\u001b[1;32m--> 355\u001b[0m     exit()\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m pygame\u001b[38;5;241m.\u001b[39mMOUSEBUTTONDOWN:\n\u001b[0;32m    357\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m event\u001b[38;5;241m.\u001b[39mpos\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "from GameMain import ConnectFourGUI\n",
    "\n",
    "gui = ConnectFourGUI()\n",
    "gui.mainMenu()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093053c5",
   "metadata": {},
   "source": [
    "## 1. Monte Carlo Tree Search (MCTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9635f21a",
   "metadata": {},
   "source": [
    "Este é o modelo que constitui o cerne deste projeto. O algoritmo pode ser dividido em 4 fases:\n",
    "\n",
    "1. **Seleção:** A partir da raiz, percorre-se a árvore selecionando sucessivamente os nós filhos de acordo com uma política (por exemplo, UCB) até chegar a um nó folha.\n",
    "\n",
    "2. **Expansão:** Se o nó folha não representa um estado terminal, um ou mais filhos são criados e adicionados à árvore.\n",
    "\n",
    "3. **Simulação:** A partir do novo nó, realiza-se uma simulação (jogadas aleatórias) até que seja alcançado um estado terminal.\n",
    "\n",
    "4. **Retropropagação:** O resultado da simulação é propagado de volta pela árvore, atualizando os nós visitados de acordo com a estatística selecionada.\n",
    "\n",
    "Esses passos são repetidos um número predefinidos de vezes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae437a4",
   "metadata": {},
   "source": [
    "## Aplicação Prática"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62c9371",
   "metadata": {},
   "source": [
    "No contexto deste projeto, cada nó representa uma posição do tabuleiro, e cada aresta uma jogada válida, tendo portanto cada nó como seus filhos os estados que resultam de jogadas válidas. Assim sendo, o modelo é chamado uma vez por jogada e, dado o tabuleiro atual,simula uma quantidade consideravél de jogos possíveis e retorna a coluna à qual estiver associada o maior número de visitas (decisão discutida adiante).\n",
    "\n",
    "Segue-se o código da classe MCTS como descrito [neste ficheiro](MCTS/MCTS.py), e uma breve descrição do seu funcionamento:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d09dbe",
   "metadata": {},
   "source": [
    "```python\n",
    "import math\n",
    "import random\n",
    "from typing import Tuple, Any, List, Union\n",
    "\n",
    "import utils.config as config\n",
    "\n",
    "from Game.ConnectFour import ConnectFour\n",
    "from MCTS.node import Node\n",
    "\n",
    "\n",
    "class MonteCarlo_Single(object):\n",
    "    \"\"\"\n",
    "    Monte Carlo Tree Search algorithm.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    search(root: Node) -> int\n",
    "        Search the best move from the root node.\n",
    "     selection(node: Node, turn: int) -> (Node, int)\n",
    "        Select the best node to expand.\n",
    "    expansion(node: Node) -> Node\n",
    "        Expand the node by adding a new child.\n",
    "    simulation(state_init: ConnectFour, turn: int) -> float\n",
    "        Simulate a random game from the initial state.\n",
    "    backpropagation(node: Node, reward: float, turn: int) -> None\n",
    "        Backpropagate the reward of the simulation to the root node.\n",
    "    best_child(node: Node) -> Node\n",
    "        Return the best child of the node.\n",
    "    \"\"\"\n",
    "    def __init__(self, iteration: int = config.ITERATION, exploration: float = config.EXPLORATION, debug: bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the Monte Carlo Tree Search algorithm.\n",
    "        \"\"\"\n",
    "        self.iteration = iteration\n",
    "        self.exploration = exploration\n",
    "        if debug:\n",
    "            print(f\"Monte Carlo Tree Search: iteration={iteration}, exploration={exploration}\")\n",
    "\n",
    "    def search(self, root: Node) -> tuple[Any, list[Any]]:\n",
    "        \"\"\"\n",
    "        Search the best move from the root node.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        root: the root node of the search tree\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int: the best move\n",
    "        \"\"\"\n",
    "        for _ in range(self.iteration):\n",
    "            node, turn = self.selection(root, -1)\n",
    "            reward = self.simulation(node.state, turn)\n",
    "            self.backpropagation(node, reward, turn)\n",
    "\n",
    "        prob = []\n",
    "        for child in root.children:\n",
    "            prob.append(child.visits / root.visits)\n",
    "\n",
    "        ans = max(root.children, key=lambda c: c.visits)\n",
    "        return ans.state.last_move[1], prob\n",
    "\n",
    "    def selection(self, node: Node, turn: int) -> tuple[Node, int]:\n",
    "        \"\"\"\n",
    "        Select the best node to expand.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        node: the node to start the selection from\n",
    "        turn: the turn of the player who played the move leading to this node\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        node: the node to expand\n",
    "        turn: the turn of the player who played the move leading to this node\n",
    "        \"\"\"\n",
    "        while not node.is_terminal():\n",
    "            if not node.fully_explored():\n",
    "                return self.expansion(node), -1 * turn\n",
    "            else:\n",
    "                node = self.best_child(node)\n",
    "                turn *= -1\n",
    "\n",
    "        return node, turn\n",
    "\n",
    "    @staticmethod\n",
    "    def expansion(node: Node) -> Node:\n",
    "        \"\"\"\n",
    "        Expand the node by adding a new child.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        node: the node to expand\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        node: the new child\n",
    "        \"\"\"\n",
    "        free_cols = node.state.legal_moves()\n",
    "\n",
    "        for col in free_cols:\n",
    "            if col not in node.children_move:\n",
    "                new_state = node.state.copy()\n",
    "                new_state.play(col)\n",
    "                node.add_child(new_state, col)\n",
    "                break\n",
    "\n",
    "        return node.children[-1]\n",
    "\n",
    "    @staticmethod\n",
    "    def simulation(state_init: ConnectFour, turn: int) -> float:\n",
    "        \"\"\"\n",
    "        Simulate a random game from the initial state.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state_init: the initial state of the game\n",
    "        turn: the turn of the player who played the move leading to this node\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        reward: the reward of the simulated game\n",
    "        \"\"\"\n",
    "        state = state_init.copy()\n",
    "\n",
    "        while not state.is_over():\n",
    "            state.play(random.choice(state.legal_moves()))\n",
    "            turn *= -1\n",
    "\n",
    "        reward_bool = state.is_over()\n",
    "\n",
    "        if reward_bool and turn == -1:\n",
    "            reward = 1.0\n",
    "        elif reward_bool and turn == 1:\n",
    "            reward = -1.0\n",
    "        else:\n",
    "            reward = 0.0\n",
    "        return reward\n",
    "\n",
    "    @staticmethod\n",
    "    def backpropagation(node: Node, reward: float, turn: int) -> None:\n",
    "        \"\"\"\n",
    "        Backpropagate the reward of the simulation to the root node.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        node: the node to start the backpropagation from\n",
    "        reward: the reward of the simulation\n",
    "        turn: the turn of the player who played the move leading to this node\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        none\n",
    "        \"\"\"\n",
    "        while node is not None:\n",
    "            node.visits += 1\n",
    "            node.reward -= turn * reward\n",
    "            node = node.parent\n",
    "            turn *= -1\n",
    "\n",
    "    def best_child(self, node: Node) -> Node:\n",
    "        \"\"\"\n",
    "        Return the best child of the node.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        node: the node to select the best child from\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        node: the best child\n",
    "        \"\"\"\n",
    "        best_score = -float(\"inf\")\n",
    "        best_children = None\n",
    "\n",
    "        for child in node.children:\n",
    "            exploitation = child.reward / child.visits\n",
    "            exploration = math.sqrt(math.log2(node.visits) / child.visits)\n",
    "            score = exploitation + self.exploration * exploration\n",
    "\n",
    "            if score == best_score:\n",
    "                if child.visits > best_children.visits:\n",
    "                    best_children = child\n",
    "            elif score > best_score:\n",
    "                best_score = score\n",
    "                best_children = child\n",
    "\n",
    "        return best_children\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fca676",
   "metadata": {},
   "source": [
    "### Explicação das Funções da Classe\n",
    "\n",
    "- **`__init__`**  \n",
    "    Inicializa o algoritmo MCTS, definindo o número de iterações e o parâmetro de exploração.\n",
    "\n",
    "- **`search`**  \n",
    "    Executa o ciclo principal do MCTS: seleção, expansão, simulação e retropropagação, retornando a melhor jogada e os scores associados a cada filho da raiz.\n",
    "\n",
    "- **`selection`**  \n",
    "    Percorre a árvore a partir de um nó, seguindo a política de seleção (ex: UCB), até encontrar um nó folha ou não totalmente explorado.\n",
    "\n",
    "- **`expansion`**  \n",
    "    Expande um nó folha, criando e adicionando um novo filho correspondente a uma jogada ainda não explorada.\n",
    "\n",
    "- **`simulation`**  \n",
    "    Realiza uma simulação (jogo aleatório) a partir do estado atual até um estado terminal, retornando a recompensa do resultado.\n",
    "\n",
    "- **`backpropagation`**  \n",
    "    Propaga o resultado da simulação de volta pela árvore, atualizando as estatísticas dos nós visitados.\n",
    "\n",
    "- **`best_child`**  \n",
    "    Seleciona o melhor filho de um nó com base no critério de exploration/exploitation (UCB), para guiar a busca nas próximas iterações.\n",
    "\n",
    "Ou seja, a escolha de uma jogada (executada pela função `search`) executa as 4 fases mencionadas acima, iteradas tantas vezes quantas as definidas no ficheiro [config.py](utils/config.py), para cada dificuldade selecionada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c39e60",
   "metadata": {},
   "source": [
    "### UCB\n",
    "Utilizamos como métrica para avaliação dos nodes o UCB, a estatística mais comum em implementações de MCTS, e que pode ser descrita pela seguinte fórmula:\n",
    "\n",
    "$$\n",
    "UCB = \\frac{w_i}{s_i} + c \\sqrt{\\frac{\\ln s_p}{s_i}}\n",
    "$$\n",
    "\n",
    "onde:\n",
    "\n",
    "- $w_i$: número de vitórias do nó $i$\n",
    "- $s_i$: número de simulações do nó $i$\n",
    "- $s_p$: número de simulações do nó pai\n",
    "- $c$: parâmetro de *exploitation*\n",
    "\n",
    "Em que $c$ constitui uma constante que equilibra o quanto a *exploration* é favorecida sobre a *exploitation*. Esta constante, neste projeto está também definida no ficheiro de [configuração](utils/config.py) e toma o valor de $1.414$, isto é, aproximadamente $\\sqrt{2}$, também um valor muito usado por defeito nestas áreas.\n",
    "\n",
    "Em específico, o UCB é calculado nestas linhas do ficheiro [MCTS.py](MCTS/MCTS.py), na função `best_child`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0ba6c5",
   "metadata": {},
   "source": [
    "```python\n",
    "exploitation = child.reward / child.visits\n",
    "exploration = math.sqrt(math.log2(node.visits) / child.visits)\n",
    "score = exploitation + self.exploration * exploration\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5df310",
   "metadata": {},
   "source": [
    "### Escolha da próxima jogada\n",
    "Acabadas as iterações do MCTS, cada jogada válida tem a si associada dois valores:\n",
    "\n",
    "* **Visited (V):** Representa a quantidade de simulações feitas sobre esse nó nas iterações de de MCTS. Vai ser, portanto, $n \\mid n \\in \\mathbb{N},\\ 0 \\leq n \\leq \\text{iter}$ em que $iter$ é o número de iterações do MCTS.\n",
    "* **Reward (R):** Representa o somatório dos rewards das iterações de MTCS. Um reward em cada iteração é definido por:\n",
    "    * **1** se o próprio ganha;\n",
    "    * **0** se há um empate;\n",
    "    * **-1** se o adversário ganha.\n",
    "\n",
    "Resta apenas definir o critério de escolha, isto é, se consideramos o melhor lance aquele que foi o mais visitado, o mais recompensado ou um equilíbrio das duas características.\n",
    "\n",
    "Testando as várias hipóteses, no entanto, verificou-se que a melhor performance é obtida ao selecionar o filho com o maior número de visitas. Isto provavelmente deve-se ao facto de um nó ter um elevado número de visitas indicar que, repetidamente, obteve os maiores valores de score UCB, revelando-se consistentemente como o mais promissor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9b1672",
   "metadata": {},
   "source": [
    "### Tempo de execução\n",
    "Ao constatar, naturalmente, que um número superior de iterações significa uma melhor performance, tentou-se executar modelos com mais e mais iterações. No entanto, neste processo o modelo começou também a demorar cada vez mais tempo a calcular a sua próxima jogada, o que piora a experiência de jogo.\n",
    "\n",
    "No sentido de corrigir isto, implementou-se uma outra classe de MCTS que utiliza *paralel processing*, executando várias iterações ao mesmo tempo, e sendo por isso significativamente mais rápido que a sua contraparte, que utiliza apenas um *core* para todas as tarefas.\n",
    "\n",
    "Eis essa outra implementação, denominada `MonteCarlo` no ficheiro [MCTS_optimized.py](MCTS/MCTS_optimized.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34a1e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import os\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from typing import Tuple, Any, Dict\n",
    "\n",
    "import utils.config as config\n",
    "from Game.ConnectFour import ConnectFour\n",
    "from MCTS.node import Node\n",
    "\n",
    "\n",
    "def worker_mcts(state: ConnectFour, iterations: int, exploration: float) -> Dict[int, Tuple[float, int]]:\n",
    "    \"\"\"\n",
    "    Each worker runs its own mini-MCTS rooted at the same state.\n",
    "    Returns: {move: (total_reward, total_visits)}\n",
    "    \"\"\"\n",
    "    root = Node(state.copy())\n",
    "\n",
    "    def selection(node: Node, turn: int) -> Tuple[Node, int]:\n",
    "        while not node.is_terminal():\n",
    "            if not node.fully_explored():\n",
    "                return expansion(node), -1 * turn\n",
    "            node = best_child(node)\n",
    "            turn *= -1\n",
    "        return node, turn\n",
    "\n",
    "    def expansion(node: Node) -> Node:\n",
    "        for col in node.state.legal_moves():\n",
    "            if col not in node.children_move:\n",
    "                new_state = node.state.copy()\n",
    "                new_state.play(col)\n",
    "                node.add_child(new_state, col)\n",
    "                break\n",
    "        return node.children[-1]\n",
    "\n",
    "    def simulation(state: ConnectFour, turn: int, max_depth: int = 20) -> float:\n",
    "        state = state.copy()\n",
    "        moves = 0\n",
    "        while not state.is_over() and moves < max_depth:\n",
    "            legal = state.legal_moves()\n",
    "            if 3 in legal:\n",
    "                state.play(3)\n",
    "            else:\n",
    "                state.play(random.choice(legal))\n",
    "            turn *= -1\n",
    "            moves += 1\n",
    "\n",
    "        if state.is_over():\n",
    "            return 1.0 if turn == -1 else -1.0\n",
    "        return 0.0\n",
    "\n",
    "    def backpropagation(node: Node, reward: float, turn: int) -> None:\n",
    "        while node is not None:\n",
    "            node.visits += 1\n",
    "            node.reward -= turn * reward\n",
    "            node = node.parent\n",
    "            turn *= -1\n",
    "\n",
    "    def best_child(node: Node) -> Node:\n",
    "        best_score = -float(\"inf\")\n",
    "        best_node = None\n",
    "        log_visits = math.log(node.visits + 1)\n",
    "        for child in node.children:\n",
    "            exploit = child.reward / (child.visits + 1e-8)\n",
    "            explore = math.sqrt(log_visits / (child.visits + 1e-8))\n",
    "            score = exploit + exploration * explore\n",
    "\n",
    "            if score == best_score:\n",
    "                if child.visits >= best_node.visits:\n",
    "                    best_node = child\n",
    "            elif score > best_score:\n",
    "                best_score = score\n",
    "                best_node = child\n",
    "        return best_node\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        node, turn = selection(root, -1)\n",
    "        reward = simulation(node.state, turn)\n",
    "        backpropagation(node, reward, turn)\n",
    "\n",
    "    move_stats = {}\n",
    "    for _, child in enumerate(root.children):\n",
    "        move = child.state.last_move[1]\n",
    "        move_stats[move] = (child.reward, child.visits)\n",
    "\n",
    "    return move_stats\n",
    "\n",
    "\n",
    "class MonteCarlo:\n",
    "\n",
    "\n",
    "    def __init__(self, iteration: int = config.ITERATION, exploration: float = config.EXPLORATION, debug: bool = False):\n",
    "        \n",
    "        self.iteration = iteration\n",
    "        self.exploration = exploration\n",
    "        self.cpu_cores = max(1, os.cpu_count() or 1)\n",
    "        self.debug = debug\n",
    "\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"Using {self.cpu_cores} CPU cores for MCTS.\")\n",
    "            print(f\"Iterations per worker: {self.iteration // self.cpu_cores}\")\n",
    "            print(f\"Exploration factor: {self.exploration}\")\n",
    "            print(f\"Total iterations: {self.iteration}\")\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "    def search(self, root: Node) -> tuple[Any, list[Any]]:\n",
    "        iterations_per_worker = self.iteration // self.cpu_cores\n",
    "\n",
    "        with ProcessPoolExecutor(max_workers=self.cpu_cores) as executor:\n",
    "            futures = [executor.submit(worker_mcts, root.state, iterations_per_worker, self.exploration)\n",
    "                       for _ in range(self.cpu_cores)]\n",
    "\n",
    "            all_stats = [f.result() for f in futures]\n",
    "\n",
    "        merged_stats: Dict[int, Tuple[float, int]] = {}\n",
    "\n",
    "        for stat in all_stats:\n",
    "            for move, (reward, visits) in stat.items():\n",
    "                if move not in merged_stats:\n",
    "                    merged_stats[move] = (reward, visits)\n",
    "                else:\n",
    "                    r, v = merged_stats[move]\n",
    "                    merged_stats[move] = (r + reward, v + visits)\n",
    "\n",
    "        for move, (reward, visits) in merged_stats.items():\n",
    "            found = False\n",
    "            for child in root.children:\n",
    "                if child.state.last_move[1] == move:\n",
    "                    child.reward += reward\n",
    "                    child.visits += visits\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                new_state = root.state.copy()\n",
    "                new_state.play(move)\n",
    "                new_child = Node(new_state, root)\n",
    "                new_child.reward = reward\n",
    "                new_child.visits = visits\n",
    "                root.children.append(new_child)\n",
    "                root.children_move.append(move)\n",
    "            root.visits += visits\n",
    "\n",
    "        prob = [child.visits / root.visits for child in root.children]\n",
    "\n",
    "        ans = max(root.children, key=lambda c: c.visits)\n",
    "        return ans.state.last_move[1], prob\n",
    "\n",
    "    def best_child(self, node: Node) -> Node:\n",
    "        best_score = -float(\"inf\")\n",
    "        best_children = None\n",
    "        log_parent_visits = math.log(node.visits + 1)\n",
    "\n",
    "        for child in node.children:\n",
    "            exploitation = child.reward / (child.visits + 1e-8)\n",
    "            exploration = math.sqrt(log_parent_visits / (child.visits + 1e-8))\n",
    "            score = exploitation + self.exploration * exploration\n",
    "\n",
    "            if score == best_score:\n",
    "                if child.visits >= best_children.visits:\n",
    "                    best_children = child\n",
    "            elif score > best_score:\n",
    "                best_score = score\n",
    "                best_children = child\n",
    "\n",
    "        return best_children"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de384cb5",
   "metadata": {},
   "source": [
    "Mesmo assim, provou-se que *paralel processing* não é sempre a solução mais rápida. Isto acontece porque, essencialmente cada *core* do CPU está a realizar MCTS na sua própria árvore e, apenas quando **todos os *cores*** já tenham acabado as suas tarefas é que todas as árvores podem ser unidas, o que computacionalmente é trabalhoso.\n",
    "\n",
    "Assim, estudando este tema mais a fundo, chegou-se à conclusão que a classe `MonteCarlo` é mais eficiente que a classe `MonteCarlo_Single` a partir das **5000 iterações**. Assim sendo, dependedo do modo de jogo selecionado, e dependendo da dificuldade selecionada (ou do número de iterações selecionadas no caso de AI vs AI) seleciona-se o modelo mais rápido para a situação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dee7e3",
   "metadata": {},
   "source": [
    "### Visualização da árvore\n",
    "\n",
    "Finalmente, no sentido de melhor compreender o funcionamento do modelo, e mesmo para *debugging*, criou-se um ficheiro [Visualize_MCtree.py](utils/Visualize_MCtree.py) que, ao ser implementado na [GameMain](GameMain.py) permite ao jogador ativar uma nova funcionalidade do **Modo de Debugging**.\n",
    "\n",
    "Este modo ativa prints de debug, que contêm informações como:\n",
    "\n",
    "- O tempo de resposta da IA\n",
    "- Quantos *cores* do CPU estão a ser usados (se estiver a ser usado mais que um)\n",
    "- O *score* dos vários nós\n",
    "- Entre outros\n",
    "\n",
    "Para além disso, selecionando o modo Player vs AI e jogando contra o modelo, a cada lance feito pelo MTCS, desenhamos um grafo que representa o estado atual e os próximos estados possíveis, bem como as estatísticas a eles associados.<br>\n",
    "Eis a visulização de uma possível árvore: <br><br>\n",
    "![](img/MCTStree.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5f666c",
   "metadata": {},
   "source": [
    "### Monte Carlo Benchmarks\n",
    "\n",
    "Na tentativa de compreender o tempo gasto por número de iterações pelo Monte Carlo Tree Search singlethread e multithread, obtiveram-se os seguintes resultados:\n",
    "<br><br>\n",
    "![](img/MCTS500.png)\n",
    "<br><br>\n",
    "![](img/MCTS5000.png)\n",
    "<br><br>\n",
    "![](img/MCTS10000.png)\n",
    "\n",
    "Como se pode oberservar, conclui-se que o **MCTS em singlethread apresenta melhor performance em _baixas iterações_**, enquanto o **MCTS em multithread tem melhor desempenho com _altas iterações_**.\n",
    "\n",
    "  - Isto deve-se ao facto de que, com poucas iterações, a **complexidade temporal da própria pesquisa** do MCTS é **menor** do que a **complexidade de junção das árvores geradas por cada core**, favorecendo a versão em singlethread.\n",
    "  - Já quando o número de iterações ultrapassa as **5000**, a **complexidade da pesquisa torna-se dominante**, tornando a versão multithread **mais eficiente**.\n",
    "\n",
    "> Nota: ao executar uma pesquisa MCTS na GUI, os tempos são maiores do que os apresentados nos gráficos acima. Isto deve-se à complexidade temporal das funções auxiliares da GUI, que retardam a pesquisa do algoritmo Monte Carlo.\n",
    "\n",
    "\n",
    "Por terem sido implementadas soluções de Monte Carlo em singlethread e multithread, surgiram dúvidas quanto à **equidade das decisões entre as versões singlethread e multithread para a mesma posição**, dado que a árvore de decisão multithread seria menos iterada por core. <br><br>\n",
    "Foram obtidos os seguintes dados relativamente à diferença percentual das decisões das diferentes versões para a mesma posição:<br><br>\n",
    "***Percentage of different moves for easy level:** 34.75%*<br>\n",
    "***Percentage of different moves for medium level:** 25.20%*<br>\n",
    "***Percentage of different moves for hard level:** 25.73%*<br><br>\n",
    "Assim, conclui-se que as classificações para as diferents versões singlethread e multithread diferem entre si. Este facto não intui que uma das versões performa pior, apenas que classifica diferente.\n",
    "<br><br>\n",
    "*(outputs retirados no notebook MCTS_benchmarks.ipynb)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09e79d2",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
    "## Introdução às Decision Trees\n",
    "\n",
    "As **Decision Trees** são algoritmos de aprendizagem supervisionada utilizados em tarefas de **classificação** e **regressão**. Funcionam através de uma divisão recursiva dos dados com base em regras de decisão simples, formando uma estrutura em forma de árvore.\n",
    "\n",
    "Cada divisão é guiada por uma métrica de qualidade, sendo a mais comum o **Information Gain**, que mede a redução de **entropia** após uma divisão, ou seja, o quanto uma determinada feature contribui para separar eficazmente as classes.\n",
    "\n",
    "## Aplicação no Projeto\n",
    "\n",
    "Neste projeto, utilizamos uma árvore de decisão para **prever a jogada ótima** (i.e., a coluna a jogar) a partir de um estado do tabuleiro no jogo *4 em linha*. A jogada considerada ótima é aquela que seria escolhida por um agente **Monte Carlo Tree Search (MCTS)** com **10.000 iterações**.\n",
    "\n",
    "## Geração do Dataset\n",
    "\n",
    "Para treinar a árvore de decisão, foi gerado um **dataset supervisionado** com aproximadamente **500 jogos simulados**, a partir dos quais foram extraídas diversas posições intermédias com respetiva jogada ideal anotada.\n",
    "\n",
    "## Evolução da Representação do Dataset\n",
    "\n",
    "### Estrutura Inicial\n",
    "\n",
    "Na fase inicial do projeto, o dataset foi construído com base numa **representação direta do estado do tabuleiro** do jogo *4 em linha*. Cada linha do dataset correspondia a um momento específico de um jogo simulado, e era composta pelos seguintes elementos:\n",
    "\n",
    "- **Um único vetor** que representava o tabuleiro completo:\n",
    "  - Cada célula da grelha era codificada como:\n",
    "    - `0` → célula vazia\n",
    "    - `1` → peça do jogador 1\n",
    "    - `-1` → peça do jogador 2\n",
    "  - A ordem dos elementos era **coluna a coluna**, **do topo para a base**, espelhando a forma se interpreta uma matriz.\n",
    "- Uma coluna adicional com o **número total de peças** jogadas até ao momento.\n",
    "- Uma coluna que indicava o **jogador atual** a jogar (1 ou -1).\n",
    "- A coluna de **output** representava a **coluna ideal** para jogar, determinada por um agente **Monte Carlo Tree Search (MCTS)** com 10.000 iterações.\n",
    "\n",
    "### Nova Estrutura do Dataset\n",
    "\n",
    "Inspirado por abordagens usadas no treino de agentes para o jogo **Go** ([neste artigo](https://jonathan-hui.medium.com/alphago-how-it-works-technically-26ddcc085319)), a representação do estado do jogo foi reformulada para melhor refletir a informação posicional de forma explícita e neutra. O estado do tabuleiro é agora representado da seguinte forma:\n",
    "\n",
    "- **Dois tabuleiros binários**, cada um com as mesmas dimensões do tabuleiro original (6x7):\n",
    "  - Um tabuleiro representa as posições ocupadas pelo **Jogador 1** (`1` para peça presente, `0` caso contrário).\n",
    "  - O outro representa as posições do **Jogador 2**, com a mesma codificação.\n",
    "- Cada entrada do dataset inclui:\n",
    "  - Os dois vetores resultantes do **flattening** dos tabuleiros.\n",
    "  - Uma feature adicional com o **número total de peças** jogadas até ao momento.\n",
    "  - A **coluna de output** com a jogada ideal sugerida pelo MCTS (com 10.000 simulações).\n",
    "\n",
    "Esta nova representação não só oferece uma **separação clara da informação entre os dois agentes**, como também permite que o modelo **aprenda padrões estratégicos específicos de cada jogador**.\n",
    "\n",
    "Eis a estrutura dos nosso dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20dad9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player1_cel1</th>\n",
       "      <th>player1_cel2</th>\n",
       "      <th>player1_cel3</th>\n",
       "      <th>player1_cel4</th>\n",
       "      <th>player1_cel5</th>\n",
       "      <th>player1_cel6</th>\n",
       "      <th>player1_cel7</th>\n",
       "      <th>player1_cel8</th>\n",
       "      <th>player1_cel9</th>\n",
       "      <th>player1_cel10</th>\n",
       "      <th>...</th>\n",
       "      <th>player2_cel35</th>\n",
       "      <th>player2_cel36</th>\n",
       "      <th>player2_cel37</th>\n",
       "      <th>player2_cel38</th>\n",
       "      <th>player2_cel39</th>\n",
       "      <th>player2_cel40</th>\n",
       "      <th>player2_cel41</th>\n",
       "      <th>player2_cel42</th>\n",
       "      <th>pieces</th>\n",
       "      <th>played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14734</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14735</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14736</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14737</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14738</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14739 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       player1_cel1  player1_cel2  player1_cel3  player1_cel4  player1_cel5  \\\n",
       "0                 0             0             0             0             0   \n",
       "1                 0             0             0             0             0   \n",
       "2                 0             0             0             0             0   \n",
       "3                 0             0             0             0             0   \n",
       "4                 0             0             0             0             0   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "14734             0             0             0             1             0   \n",
       "14735             0             0             1             0             0   \n",
       "14736             0             1             0             1             0   \n",
       "14737             0             0             1             0             0   \n",
       "14738             0             1             0             1             1   \n",
       "\n",
       "       player1_cel6  player1_cel7  player1_cel8  player1_cel9  player1_cel10  \\\n",
       "0                 0             0             0             0              0   \n",
       "1                 0             0             0             0              0   \n",
       "2                 0             0             0             0              0   \n",
       "3                 0             0             0             0              0   \n",
       "4                 0             0             0             0              0   \n",
       "...             ...           ...           ...           ...            ...   \n",
       "14734             0             0             0             0              1   \n",
       "14735             0             0             0             1              0   \n",
       "14736             0             0             0             0              1   \n",
       "14737             0             1             0             1              0   \n",
       "14738             0             0             0             0              1   \n",
       "\n",
       "       ...  player2_cel35  player2_cel36  player2_cel37  player2_cel38  \\\n",
       "0      ...              0              0              0              0   \n",
       "1      ...              0              0              0              0   \n",
       "2      ...              0              0              0              0   \n",
       "3      ...              0              0              0              0   \n",
       "4      ...              0              0              0              0   \n",
       "...    ...            ...            ...            ...            ...   \n",
       "14734  ...              0              0              0              1   \n",
       "14735  ...              1              1              1              0   \n",
       "14736  ...              0              0              0              1   \n",
       "14737  ...              1              1              1              0   \n",
       "14738  ...              0              0              0              1   \n",
       "\n",
       "       player2_cel39  player2_cel40  player2_cel41  player2_cel42  pieces  \\\n",
       "0                  0              0              0              0       0   \n",
       "1                  1              0              0              0       1   \n",
       "2                  0              1              0              0       2   \n",
       "3                  1              0              0              0       3   \n",
       "4                  0              1              0              0       4   \n",
       "...              ...            ...            ...            ...     ...   \n",
       "14734              0              1              1              1      30   \n",
       "14735              1              0              0              0      31   \n",
       "14736              0              1              1              1      32   \n",
       "14737              1              0              0              0      33   \n",
       "14738              0              1              1              1      34   \n",
       "\n",
       "       played  \n",
       "0           3  \n",
       "1           4  \n",
       "2           3  \n",
       "3           3  \n",
       "4           4  \n",
       "...       ...  \n",
       "14734       1  \n",
       "14735       6  \n",
       "14736       4  \n",
       "14737       0  \n",
       "14738       0  \n",
       "\n",
       "[14739 rows x 86 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_file = os.path.join('datasets', 'monte_carlo_AI_VS_AI.csv')\n",
    "data = pd.read_csv(data_file, delimiter=';')\n",
    "data['played'] = data['played'].astype(int)\n",
    "data\n",
    "\n",
    "cel_columns = [f'cel{i}' for i in range(1, 43)]\n",
    "\n",
    "# Update the DataFrame\n",
    "data.loc[data['turn'] == -1, cel_columns] *= -1  # Flip -1 to 1 and 1 to -1\n",
    "data['turn'] = 1  # Change turn to 1\n",
    "data.drop(columns=['turn'], inplace=True)\n",
    "data\n",
    "\n",
    "# Generate column names\n",
    "c = [f\"player1_cel{i}\" for i in range(1, 43)]\n",
    "\n",
    "# Extract and rename columns from the original dataset\n",
    "player_1 = data[cel_columns].copy()\n",
    "player_1.columns = c  # Rename columns to desired format\n",
    "\n",
    "# Replace -1 with 0\n",
    "player_1.replace(-1, 0, inplace=True)\n",
    "\n",
    "c = [f\"player2_cel{i}\" for i in range(1, 43)]\n",
    "player_2 = data[cel_columns].copy()\n",
    "player_2.columns = c  # Rename columns to desired format\n",
    "# Replace -1 with 0\n",
    "player_2.replace(1, 0, inplace=True)\n",
    "player_2.replace(-1, 1, inplace=True)\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "data = pd.concat([player_1, player_2, data['pieces'], data['played']], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ce642",
   "metadata": {},
   "source": [
    "\n",
    " \n",
    "\n",
    "# Tentativa de Randomização das Posições\n",
    "\n",
    "Durante a fase de geração do dataset, foi inicialmente considerada a ideia de **randomizar posições do tabuleiro** em vez de as obter exclusivamente a partir de jogos completos simulados com agentes MCTS.\n",
    "\n",
    "A motivação por trás desta abordagem era: \n",
    "- Aumentar a diversidade de posições no dataset\n",
    "- Reduzir o tempo necessário para simular jogos completos\n",
    "- Explorar casos de jogo menos prováveis, mas ainda legais\n",
    "\n",
    "### Estratégia Testada\n",
    "\n",
    "O processo consistia em:\n",
    "1. Gerar posições aleatórias válidas (respeitando as regras do 4 em linha, como gravidade das peças)\n",
    "2. Avaliar essas posições usando o agente MCTS com 10.000 iterações\n",
    "3. Adicionar a posição e a jogada recomendada ao dataset\n",
    "\n",
    "Apesar de parecer viável, esta abordagem foi **desaconselhada pelo professor da cadeira** a qual foi, então, descartada.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057f2ba1",
   "metadata": {},
   "source": [
    "# Algoritmo ID3 - Implementação da Árvore de Decisão\n",
    "\n",
    "Neste capítulo será abordada a implementação do algoritmo **ID3** para construção de Decision Trees , conforme desenvolvido no ficheiro [ID3Tree.py](DecisionTree/ID3Tree.py).\n",
    "\n",
    "A implementação encontra-se encapsulada numa classe denominada `ID3Tree`, a qual integra os métodos essenciais para:\n",
    "- Cálculo da entropia de um conjunto de rótulos,\n",
    "- Determinação do ganho de informação,\n",
    "- Construção recursiva da árvore de decisão,\n",
    "- Classificação de novos exemplos.\n",
    "\n",
    "\n",
    "\n",
    "## Método `entropy`\n",
    "\n",
    "O método `entropy` é definido na classe `ID3Tree` e tem como função calcular a **entropia** de um conjunto de rótulos, o que corresponde a uma medida quantitativa da **impureza** ou incerteza inerente a esse conjunto.\n",
    "\n",
    "```python\n",
    "def entropy(self, labels):\n",
    "    \"\"\"\n",
    "    Calculate the entropy of a set of labels.\n",
    "    - labels: List of class labels.\n",
    "    \"\"\"\n",
    "    total = len(labels)\n",
    "    counter = Counter(labels)  # Count occurrences of each label\n",
    "    return -sum((count / total) * math.log2(count / total) for count in counter.values())\n",
    "```\n",
    "\n",
    "### Definição e Justificação\n",
    "\n",
    "A entropia é uma métrica fundamental na teoria da informação, utilizada para quantificar a quantidade de incerteza num conjunto de dados. No contexto do algoritmo ID3, é empregue para medir a heterogeneidade dos rótulos em cada subconjunto de dados, servindo de base para a escolha dos atributos que melhor segmentam a informação.\n",
    "\n",
    "Formalmente, a entropia $H(S)$ de um conjunto $S$ contendo $C$ classes distintas é dada por:\n",
    "\n",
    "$$\n",
    "H(S) = - \\sum_{i=1}^{C} p_i \\log_2(p_i)\n",
    "$$\n",
    "\n",
    "onde $p_i$ representa a proporção de elementos pertencentes à classe $i$ no conjunto $S$.\n",
    "\n",
    "### Análise do Método\n",
    "\n",
    "- **Cálculo do total de amostras**:  \n",
    "  O número total de rótulos no conjunto é determinado através de `total = len(labels)`.\n",
    "\n",
    "- **Contagem da frequência de cada classe**:  \n",
    "  Utiliza-se a estrutura `Counter` da biblioteca `collections` para obter a frequência absoluta de cada classe.\n",
    "\n",
    "- **Cálculo da entropia**:  \n",
    "\n",
    "  Para cada classe, calcula-se a frequência relativa  $ p_i = \\frac{\\text{count}}{\\text{total}} $ e avalia-se o termo $ -p_i \\log_2(p_i) $. A soma destes termos para todas as classes resulta no valor da entropia do conjunto.\n",
    "\n",
    "### Relevância para o Algoritmo ID3\n",
    "\n",
    "O cálculo da entropia é indispensável para o cálculo subsequente do **ganho de informação** (information gain), que avalia a eficácia da segmentação do conjunto de dados por cada atributo. O atributo que proporciona a maior redução da entropia é escolhido para a divisão do nó, conduzindo a uma árvore de decisão mais eficaz e informativa.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd94ccf",
   "metadata": {},
   "source": [
    "\n",
    "### Função `id3_continuous`\n",
    "\n",
    "Esta função avalia o ganho de informação associado a um **atributo contínuo**.\n",
    "\n",
    "```python\n",
    "def id3_continuous(self, data, attribute):\n",
    "    \"\"\"\n",
    "    Calculate the information gain for a continuous attribute.\n",
    "    - data: Training data.\n",
    "    - attribute: The attribute to evaluate.\n",
    "    \"\"\"\n",
    "    idx = self.attributes.index(attribute)\n",
    "    values = sorted(set(row[idx] for row in data))  # Unique sorted values of the attribute\n",
    "    if len(values) == 1:\n",
    "        return -1, None  # No split possible if only one unique value\n",
    "\n",
    "    # Calculate potential thresholds\n",
    "    thresholds = [(values[i] + values[i + 1]) / 2 for i in range(len(values) - 1)]\n",
    "    base_entropy = self.entropy([row[-1] for row in data])  # Entropy of the entire dataset\n",
    "\n",
    "    best_gain, best_thresh = -1, None\n",
    "    for t in thresholds:\n",
    "        # Split data into above and below threshold\n",
    "        above = [row for row in data if row[idx] >= t]\n",
    "        below = [row for row in data if row[idx] < t]\n",
    "        p, n = len(above) / len(data), len(below) / len(data)\n",
    "        # Calculate information gain\n",
    "        gain = base_entropy - p * self.entropy([r[-1] for r in above]) - n * self.entropy([r[-1] for r in below])\n",
    "        if gain > best_gain:\n",
    "            best_gain, best_thresh = gain, t\n",
    "    return best_gain, best_thresh\n",
    "```\n",
    "\n",
    "#### Explicação técnica\n",
    "\n",
    "1. **Extração e ordenação dos valores do atributo**\n",
    "\n",
    "   ```python\n",
    "   values = sorted(set(row[idx] for row in data))\n",
    "   ```\n",
    "\n",
    "   São considerados apenas os valores únicos e ordenados do atributo contínuo.\n",
    "\n",
    "2. **Geração de limiares candidatos**\n",
    "\n",
    "   São gerados todos os possíveis pontos médios entre pares consecutivos de valores:\n",
    "\n",
    "   $$\n",
    "   \\text{threshold}_i = \\frac{v_i + v_{i+1}}{2}\n",
    "   $$\n",
    "\n",
    "   Estes limiares são os pontos de corte candidatos para dividir o conjunto de dados.\n",
    "\n",
    "3. **Cálculo do ganho de informação**\n",
    "\n",
    "   Para cada limiar $ t $, divide-se o conjunto em duas partes:\n",
    "   - Acima do limiar: $ D_{\\geq t} $\n",
    "   - Abaixo do limiar: $ D_{< t} $\n",
    "\n",
    "   O ganho de informação é então calculado como:\n",
    "\n",
    "   $$\n",
    "   \\text{Gain}(t) = H(D) - p \\cdot H(D_{\\geq t}) - (1 - p) \\cdot H(D_{< t})\n",
    "   $$\n",
    "\n",
    "   onde $ H(D) $ é a entropia do conjunto total e $ p $ é a proporção de dados em $ D_{\\geq t} $.\n",
    "\n",
    "4. **Resultado**\n",
    "\n",
    "   A função devolve o limiar $ t $ que gera o maior ganho de informação, juntamente com o valor desse ganho.\n",
    "\n",
    "\n",
    "\n",
    "### Função `id3_discrete`\n",
    "\n",
    "Esta função calcula o ganho de informação para atributos **discretos**, ou seja, com um número finito de categorias.\n",
    "\n",
    "```python\n",
    "def id3_discrete(self, data, attribute):\n",
    "    \"\"\"\n",
    "    Calculate the information gain for a discrete attribute.\n",
    "    - data: Training data.\n",
    "    - attribute: The attribute to evaluate.\n",
    "    \"\"\"\n",
    "    idx = self.attributes.index(attribute)\n",
    "    base_entropy = self.entropy([row[-1] for row in data])  # Entropy of the entire dataset\n",
    "    values = set(row[idx] for row in data)  # Unique values of the attribute\n",
    "\n",
    "    remainder = 0\n",
    "    for val in values:\n",
    "        # Subset of data where the attribute equals the current value\n",
    "        subset = [row for row in data if row[idx] == val]\n",
    "        remainder += (len(subset) / len(data)) * self.entropy([row[-1] for row in subset])\n",
    "\n",
    "    return base_entropy - remainder, None\n",
    "```\n",
    "\n",
    "#### Explicação técnica\n",
    "\n",
    "Neste caso, o conjunto de dados é particionado em subconjuntos distintos consoante os valores únicos do atributo.\n",
    "\n",
    "O ganho de informação é calculado da seguinte forma:\n",
    "\n",
    "- Entropia inicial: $ H(D) $\n",
    "- Resto (_remainder_):\n",
    "\n",
    "  $$\n",
    "  \\text{Remainder}(A) = \\sum_{v \\in \\text{Values}(A)} \\frac{|D_v|}{|D|} \\cdot H(D_v)\n",
    "  $$\n",
    "\n",
    "  onde $ D_v $ representa o subconjunto de dados para os quais o atributo $ A = v $.\n",
    "\n",
    "- Finalmente, o ganho é:\n",
    "\n",
    "  $$\n",
    "  \\text{Gain}(A) = H(D) - \\text{Remainder}(A)\n",
    "  $$\n",
    "\n",
    "Como não há limiar em atributos discretos, o segundo valor devolvido pela função é `None`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1806d6",
   "metadata": {},
   "source": [
    "## Geração de Regras a Partir da Árvore - `build_rules`\n",
    "\n",
    "Uma das grandes vantagens da utilização de Decision Trees  é a sua **capacidade de explicação**. A função `build_rules` tem como objetivo transformar a árvore gerada pelo algoritmo ID3 numa **lista de regras legíveis**, onde cada regra corresponde a um caminho da raiz até uma folha, com as respetivas condições e classificação final.\n",
    "\n",
    "``` python\n",
    "def build_rules(self, tree=None, premises=None):\n",
    "    \"\"\"\n",
    "    Build a list of rules from the decision tree.\n",
    "    - tree: The decision tree (default is the trained tree).\n",
    "    - premises: List of premises leading to the current node.\n",
    "    \"\"\"\n",
    "    tree = self.tree if tree is None else tree\n",
    "    premises = premises or []\n",
    "    rules = []\n",
    "\n",
    "    for node, branches in tree.items():\n",
    "        for value, subtree in branches.items():\n",
    "            # Add the current condition to the premises\n",
    "            new_premise = premises + [(node.attribute, value, node.threshold) if node.threshold is not None else (node.attribute, '=', value)]\n",
    "            if isinstance(subtree, dict):\n",
    "                # Recursively build rules for subtrees\n",
    "                rules.extend(self.build_rules(subtree, new_premise))\n",
    "            else:\n",
    "                # Create a rule for a leaf node\n",
    "                rules.append(Rule(self.attributes, new_premise, subtree))\n",
    "    return rules\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### Explicação Técnica\n",
    "\n",
    "#### Parâmetros:\n",
    "\n",
    "- **`tree`**: Subárvore atual. Caso não seja fornecida, utiliza-se a árvore completa treinada (`self.tree`).\n",
    "- **`premises`**: Lista de condições acumuladas ao longo do caminho da raiz até ao nó atual. Cada condição é armazenada como uma tupla.\n",
    "\n",
    "#### Objetivo:\n",
    "\n",
    "Gerar uma lista de objetos da classe `Rule`, onde cada objeto representa uma regra da forma:\n",
    "\n",
    "> **SE** (atributo1 = valor1) **E** (atributo2 ≥ threshold2) **ENTÃO** classe = X\n",
    "\n",
    "\n",
    "\n",
    "### Processo Recursivo\n",
    "\n",
    "1. **Iterar sobre os nós da árvore**:\n",
    "   A árvore é representada como um dicionário onde cada chave é um `Node` e os valores são os ramos descendentes desse nó.\n",
    "\n",
    "2. **Construção de condições (premises)**:\n",
    "   Cada nó adiciona uma nova condição à lista de `premises`. A condição é construída de forma diferente consoante se trata de um atributo contínuo ou discreto.\n",
    "\n",
    "   - Para contínuos:  \n",
    "     ```python\n",
    "     (atributo, operador, threshold)\n",
    "     ```\n",
    "     onde `operador` será `'<'` ou `'>='` consoante o ramo.\n",
    "\n",
    "   - Para discretos:\n",
    "     ```python\n",
    "     (atributo, '=', valor)\n",
    "     ```\n",
    "\n",
    "3. **Verificação do tipo de ramo**:\n",
    "   - Se o ramo ainda for um dicionário (`dict`), significa que há mais subdivisões, e a função é chamada recursivamente.\n",
    "   - Se for um valor (rótulo), significa que foi alcançada uma **folha**, e uma nova regra é criada com o conjunto atual de premissas.\n",
    "\n",
    "\n",
    "\n",
    "### Exemplo de Regra Gerada\n",
    "\n",
    "Suponhamos que a árvore contenha os seguintes ramos:\n",
    "\n",
    "- `Node(attribute='coluna_1', threshold=0.5)`:\n",
    "  - Ramo `>=`: vai para `Node(attribute='coluna_3', threshold=None)`\n",
    "    - Ramo `'=': 1` → classe `Jogador_1`\n",
    "    - Ramo `'=': 0` → classe `Jogador_2`\n",
    "\n",
    "Neste caso, as regras geradas seriam algo do género:\n",
    "\n",
    "- SE `coluna_1 ≥ 0.5` E `coluna_3 = 1` → `Classe = Jogador_1`\n",
    "- SE `coluna_1 ≥ 0.5` E `coluna_3 = 0` → `Classe = Jogador_2`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f01750",
   "metadata": {},
   "source": [
    "## Conclusão - Algoritmo ID3\n",
    "\n",
    "A aplicação do algoritmo **ID3** no contexto do jogo *4 em linha* permitiu uma primeira aproximação à criação de um modelo supervisionado com base em regras explícitas. Apesar da sua simplicidade, o ID3 revelou-se pouco eficaz quando aplicado diretamente sobre o **dataset derivado de estados de jogo simulados por MCTS**.\n",
    "\n",
    "\n",
    "\n",
    "### Resultados e Observações\n",
    "\n",
    "Durante os testes realizados, o modelo alcançou uma **accuracy entre 30% a 40% em dados de teste**, enquanto apresentava **valores superiores a 90% nos dados de treino**. Este comportamento revela a ocorrência de dois problemas fundamentais:\n",
    "\n",
    "- **Overfitting (Alta Variância)**: O modelo ajusta-se excessivamente aos dados de treino, perdendo a capacidade de generalizar para novas situações.\n",
    "- **Alta Bias estrutural**: A simplicidade do ID3 impossibilita uma estratégia mais complexa necessária para uma boa árvore de decisão no jogo de 4 em linha, especialmente em cenários com múltiplas interdependências entre jogadas.\n",
    "\n",
    "\n",
    "\n",
    "### Considerações sobre a Natureza do Problema\n",
    "\n",
    "Estes resultados eram **esperados**, dado que:\n",
    "\n",
    "- O jogo *4 em linha* é altamente estratégico e **não-linear**, com muitas combinações possíveis de jogadas dependentes do contexto.\n",
    "- O ID3 **não tem memória nem profundidade estratégica**, baseando-se apenas em partições de dados locais, sem considerar consequências futuras.\n",
    "\n",
    "\n",
    "\n",
    "### Caminhos Futuros\n",
    "\n",
    "De forma a **ultrapassar as limitações** observadas com o ID3, foram exploradas outras abordagens mais robustas e adequadas à natureza do problema:\n",
    "\n",
    "- **Bagging (Bootstrap Aggregation)**\n",
    "- **RuleSet Generalization** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6526800",
   "metadata": {},
   "source": [
    "#  Ruleset (ID3 Tree com Pruning)\n",
    "\n",
    "## Introdução Teórica\n",
    "\n",
    "Um **Ruleset** é uma representação de um modelo de decisão na forma de um conjunto explícito de **regras if-then**, derivadas geralmente de modelos base como **Decision Trees**.\n",
    "\n",
    "### Vantagens desta Implementação\n",
    "- Melhor capacidade de **generalização** por redução do overfitting ao excluir ramos com muito baixo ganho\n",
    "- **Redução** da largura e profundidade da Decision Tree gerada\n",
    "- **Melhoria** da perfomance de classificação\n",
    "\n",
    "\n",
    "### Problemas do Rulesets Implementado\n",
    "- **Custo computacional elevado** - necessário iterar por todas as regras geradas e aferir se o pruning dessa regra afeta, ou não, o ganho de informação da árvore;\n",
    "- **Complexidade Temporal elevada** - quanto maior a árvore gerada, mais tempo demorará a sua poda;\n",
    "\n",
    "\n",
    "## Pruning (Poda)\n",
    "\n",
    "A técnica de **poda** consiste em **remover condições que não gerem ganhos de informação** das regras extraídas, com o objetivo de **simplificar o Ruleset** não compromentedo - e geralmente melhorando - a sua performance. Para isso, o conjunto de dados de treino é divido em train/validation, com ratio 0.67/0.33\n",
    "\n",
    "A poda atua como um mecanismo de **regularização**, reduzindo a complexidade do modelo e prevenindo o overfitting. Os cortes e a  simplificação da árvore de decisão é feita através da seguinte lógica:\n",
    "\n",
    "```python\n",
    "\n",
    "for rule in self.rules:\n",
    "    for _ in range(len(rule.premises)):\n",
    "        acc_before = rule.accuracy(self.prune_data)\n",
    "        removed = rule.premises.pop()  # Try removing the last premise\n",
    "        if acc_before > rule.get_accuracy(self.prune_data):\n",
    "            rule.premises.append(removed)  # Restore if accuracy drops\n",
    "            break\n",
    "\n",
    "```\n",
    "\n",
    "### Explicação da Implementação:\n",
    "\n",
    "- Precorre-se as todas as regras (ramos) da árvore de decisão que queremos podar;\n",
    "- Precorre-se todas as premissas (nós) de uma dada regra;\n",
    "- Calcula-se a accuracy das previsões e, posteriormente, remove-se essa premissa e calcula-se a accuracy pós-remoção;\n",
    "- Se a accuracy antes da remoção for maior do que depois da remoção, volta-se a adcionar a premissa (a premissa tem elevado ganho de informação para a classificação em validação);\n",
    "- Se a accuracy antes da remoção não for maior, salta-se para a próxima regra (as premissas subsequentes não garantiam ganhos de informação);\n",
    "\n",
    "\n",
    "\n",
    "Esta abordagem procura um equilíbrio entre **simplicidade** e **eficácia**, e será detalhada nos tópicos seguintes com o respetivo código de implementação e análise dos resultados obtidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73913d21",
   "metadata": {},
   "source": [
    "# Bagging (Bootstrap Aggregation)\n",
    "\n",
    "## Introdução Teórica\n",
    "\n",
    "O **Bagging** (*Bootstrap Aggregation*) é uma técnica de aprendizagem em conjunto (**ensemble learning**) cujo principal objetivo é **reduzir a variância** de modelos de machine learning instáveis, como as Decision Trees.\n",
    "\n",
    "A ideia central do Bagging consiste em:\n",
    "\n",
    "1. **Gerar múltiplos subconjuntos de dados** a partir do conjunto de treino original, usando amostragem com reposição (bootstrap).\n",
    "2. **Treinar modelos independentes** sobre cada um desses subconjuntos.\n",
    "3. **Combinar os resultados** das classificações dos modelos, por maioria de voto.\n",
    "\n",
    "Esta abordagem promove a mitigação do problema de **overfitting** típico, em modelos altamente sensíveis aos dados, como é o caso do ID3, que ao agregar vários modelos individualmente imperfeitos, se complementam mutuamente.\n",
    "\n",
    "\n",
    "\n",
    "### Justificação da Aplicação no Projeto\n",
    "\n",
    "Como demonstrado no capítulo anterior, a aplicação direta do algoritmo **ID3** ao problema do jogo *4 em linha* resultou numa performance limitada, com clara evidência de **alta variância** - accuracy de treino elevada, mas fraca generalização nos dados de teste.\n",
    "\n",
    "Assim, a técnica de Bagging surge como uma **tentativa natural de aumentar a robustez do modelo** sem alterar o classificador base. Através da combinação de várias árvores ID3 treinadas em subconjuntos diferentes do dataset, esperamos atingir uma **melhoria significativa da performance**, reduzindo a variância sem comprometer em demasia o viés.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0301123d",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n",
    "Seguem, abaixo, os resultados retirados dos processos de treino e teste para cada implementação, os quais já foram referidos no relatório:\n",
    "\n",
    "\n",
    "### **Estatísticas de treino:**\n",
    "Train metrics for ID3 Tree model:<br>\n",
    "***Accuracy**:0.9092, **Precision**: 0.9098, **Recall**: 0.9092, **F1 Score:** 0.9086*<br><br>\n",
    "Train metrics for Ruleset model:<br>\n",
    "***Accuracy**: 0.8223, **Precision**: 0.8239, **Recall**: 0.8223, **F1 Score**: 0.8219*<br><br>\n",
    "Train metrics for Bagging model:<br>\n",
    "***Accuracy**: 0.8112, **Precision**: 0.8214, **Recall**: 0.8112, **F1 Score**: 0.8109*<br><br>\n",
    "\n",
    "### **Estatísticas de teste:**\n",
    "Test metrics for ID3 Tree model:<br>\n",
    "***Accuracy**: 0.7680, **Precision**: 0.7680, **Recall**: 0.7680, **F1 Score:** 0.7670*<br><br>\n",
    "![](img/cmID3.png)<br><br><br>\n",
    "Test metrics for Ruleset model:<br>\n",
    "***Accuracy**: 0.7354, **Precision**: 0.7364, **Recall**: 0.7354, **F1 Score:** 0.7352*<br><br>\n",
    "![](img/cmRuleset.png)<br><br><br>\n",
    "Test metrics for Bagging model:<br>\n",
    "***Accuracy**: 0.7364, **Precision**: 0.7505, **Recall**: 0.7364, **F1 Score:** 0.7302*<br><br>\n",
    "![](img/cmBagging.png)<br><br><br>\n",
    "\n",
    "\n",
    "*(output retirado do notebook analize_decision_tree.ipynb)*\n",
    "\n",
    "### **Feature importance**\n",
    "\n",
    "Na tentativa de compreender melhor o comportamento dos modelos de Decision Tree implementados e, consequentemente, compreender melhor as decisões do MCTS, estudou-se a `feature importance` dos modelos de Decision Tree. <br> Obtiveram-se os seguintes resultados:\n",
    "\n",
    "##### Feature Importance for ID3 model:<br>\n",
    "\n",
    "\n",
    "| Feature   | Score             |\n",
    "|---------|---------------------|\n",
    "| pieces | 0.30871352792495566 |\n",
    "| cel40  | 0.021652094021574052 |\n",
    "| cel31  | 0.020484247929462285 |\n",
    "| cel11  | 0.014016171468572088 |\n",
    "| cel18  | 0.013098982612913476 |\n",
    "\n",
    "\n",
    "Cells Rank Importance:<br>\n",
    "\n",
    "| 37 | 36 | 20 |  8 | 16 | 41 | 30 |\n",
    "|----|----|----|----|----|----|----|\n",
    "| 33 | 25 | 23 |  3 | 15 | 39 | 31 |\n",
    "| 28 | 26 | 17 |  4 |  5 | 38 | 19 |\n",
    "| 35 | 22 | 18 | 13 | 21 | 32 | 27 |\n",
    "| 29 |  9 |  2 | 40 |  7 | 34 | 10 |\n",
    "| 12 | 11 |  6 | 42 |  1 | 24 | 14 |\n",
    "\n",
    "\n",
    "Column Importances:\n",
    "- **Column 5:** 0.0736 <br>\n",
    "- **Column 3:** 0.0670 <br>\n",
    "- **Column 4:** 0.0495 <br>\n",
    "- **Column 2:** 0.0473 <br>\n",
    "- **Column 7:** 0.0472 <br>\n",
    "- **Column 1:** 0.0371 <br>\n",
    "- **Column 6:** 0.0240 <br>\n",
    "\n",
    "\n",
    "Row Importances:\n",
    "- **Row 6:** 0.0721<br>\n",
    "- **Row 5:** 0.0663<br>\n",
    "- **Row 3:** 0.0603<br>\n",
    "- **Row 4:** 0.0527<br>\n",
    "- **Row 2:** 0.0513<br>\n",
    "- **Row 1:** 0.0430<br>\n",
    "\n",
    "\n",
    "\n",
    "##### Feature Importance for Ruleset model:\n",
    "\n",
    "| Feature   | Score             |\n",
    "|---------|---------------------|\n",
    "| pieces | 0.27306077053768113 |\n",
    "| cel19  | 0.028941029940628915 |\n",
    "| cel26  | 0.02710772224424464 |\n",
    "| cel3   | 0.026707337101747504 |\n",
    "| cel11  | 0.02051024195575904 |\n",
    "\n",
    "\n",
    "Cells Rank Importance:<br>\n",
    "\n",
    "| 22 | 39 |  3 |  6 | 13 | 41 | 38 |\n",
    "|----|----|----|----|----|----|----|\n",
    "| 20 | 23 | 17 |  4 |  7 | 33 | 25 |\n",
    "| 31 | 32 |  9 | 24 |  1 | 28 | 12 |\n",
    "| 35 | 27 | 15 | 14 |  2 | 40 | 30 |\n",
    "| 34 | 26 | 10 | 42 | 19 | 21 |  8 |\n",
    "| 16 | 11 | 37 | 36 |  5 | 29 | 18 |\n",
    "\n",
    "\n",
    "Column Importances:\n",
    "- **Column 5:** 0.1045 <br>\n",
    "- **Column 3:** 0.0687 <br>\n",
    "- **Column 4:** 0.0544 <br>\n",
    "- **Column 7:** 0.0443 <br>\n",
    "- **Column 2:** 0.0341 <br>\n",
    "- **Column 1:** 0.0328 <br>\n",
    "- **Column 6:** 0.0246 <br>\n",
    "\n",
    "\n",
    "Row Importances:\n",
    "- **Row 3:** 0.0715<br>\n",
    "- **Row 1:** 0.0642<br>\n",
    "- **Row 2:** 0.0636<br>\n",
    "- **Row 4:** 0.0599<br>\n",
    "- **Row 6:** 0.0560<br>\n",
    "- **Row 5:** 0.0482<br>\n",
    "\n",
    "\n",
    "##### Feature Importance for Bagging model:\n",
    "\n",
    "| Feature   | Score             |\n",
    "|---------|---------------------|\n",
    "| pieces | 0.25732551076858157 |\n",
    "| cel3   | 0.04390351036360313 |\n",
    "| cel11  | 0.019909721360264344 |\n",
    "| cel40  | 0.01385043367470451 |\n",
    "| cel21  | 0.013740461486513198 |\n",
    "\n",
    "\n",
    "Cells Rank Importance:<br>\n",
    "\n",
    "| 27 | 36 |  1 |  7 | 23 | 40 | 21 |\n",
    "|----|----|----|----|----|----|----|\n",
    "| 35 | 22 | 26 |  2 | 13 | 37 | 15 |\n",
    "| 16 | 34 | 18 | 25 |  5 | 39 |  4 |\n",
    "| 32 | 31 | 14 | 28 |  8 | 38 | 30 |\n",
    "| 33 | 10 | 12 | 41 | 11 | 29 | 20 |\n",
    "| 17 |  6 | 19 | 42 |  3 | 24 |  9 |\n",
    "\n",
    "\n",
    "Column Importances:\n",
    "- **Column 3:** 0.0875 <br>\n",
    "- **Column 5:** 0.0684 <br>\n",
    "- **Column 7:** 0.0561 <br>\n",
    "- **Column 4:** 0.0484 <br>\n",
    "- **Column 2:** 0.0476 <br>\n",
    "- **Column 1:** 0.0394 <br>\n",
    "- **Column 6:** 0.0238 <br>\n",
    "\n",
    "\n",
    "Row Importances:\n",
    "- **Row 1:** 0.0852<br>\n",
    "- **Row 6:** 0.0641<br>\n",
    "- **Row 2:** 0.0614<br>\n",
    "- **Row 3:** 0.0587<br>\n",
    "- **Row 5:** 0.0544<br>\n",
    "- **Row 4:** 0.0475<br>\n",
    "\n",
    "<br><br>\n",
    "*(outputs retirados do notebook DT_feature_importance.ipynb)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020985e3",
   "metadata": {},
   "source": [
    "# Conclusões Finais\n",
    "\n",
    "## 1. Sobre o **Monte Carlo Tree Search (MCTS)**\n",
    "\n",
    "Ao fim deste trabalho, conclui-se que:\n",
    "\n",
    "- O algoritmo de **Monte Carlo Tree Search** implementado revelou-se _**muito eficiente**_ na pesquisa do melhor lance para uma dada posição, **necessitando de pouco tempo por decisão para vencer um humano**.\n",
    "\n",
    "- O **MCTS em singlethread apresenta melhor performance em _baixas iterações_**, enquanto o **MCTS em multithread tem melhor desempenho com _altas iterações_**.\n",
    "\n",
    "  - Isto deve-se ao facto de que, com poucas iterações, a **complexidade temporal da própria pesquisa** do MCTS é **menor** do que a **complexidade de junção das árvores geradas por cada core**, favorecendo a versão em singlethread.\n",
    "  - Já quando o número de iterações ultrapassa as **5000**, a **complexidade da pesquisa torna-se dominante**, tornando a versão multithread **mais eficiente**.\n",
    "\n",
    "- No caso do MCTS em multithread, ao **dividir o número total de iterações pelo número de cores do CPU**, surgiram dúvidas quanto à **equidade da comparação entre as versões singlethread e multithread**, dado que a árvore de decisão multithread seria menos iterada por core.\n",
    "\n",
    "  - Esta hipótese foi **confirmada**: observou-se que **aproximadamente 30% das decisões tomadas para a mesma posição diferem entre a versão singlethread e a multithread**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5147500b",
   "metadata": {},
   "source": [
    "## 2. Sobre a **Decision Tree nos Datasets Iris e AI vs AI**\n",
    "\n",
    "Ao longo desta análise, verificou-se que:\n",
    "\n",
    "- Tanto a implementação da Decision Tree ID3, quanto a Decision Tree com Prunning (Ruleset) e o ensemble por Bootstrap Aggregating (Bagging) apresentaram **accuracy superior a 90% no dataset Iris**.\n",
    "\n",
    "- Embora o modelo Bagging tenha demorado mais tempo em treino, foi o que alcançou a **melhor performance, atingindo 100% de accuracy no iris dataset**.\n",
    "\n",
    "- No dataset gerado pelos jogos de AI vs AI, observou-se uma correlação direta entre a quantidade de exemplos de treino e a performance dos modelos, devido ao comportamento do algoritmo MCTS, que prefere jogar nas colunas centrais e inicia as partidas com as mesmas aberturas.\n",
    "\n",
    "- Este comportamento gerou um défice de dados nas colunas extremas, refletindo um menor número de exemplos de treino nessas regiões, o que resultou em **overfitting**, evidenciado pelo desempenho superior no conjunto de treino em comparação ao conjunto de teste.\n",
    "\n",
    "- As métricas de desempenho no conjunto de teste ficaram entre **40% e 50%**, indicando uma queda significativa em relação ao desempenho observado no treino.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSciEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
